{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d8b2e7e",
   "metadata": {},
   "source": [
    "# Predict-Closed-Question-StackOverFlow Using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974943b9",
   "metadata": {},
   "source": [
    "## Step-1:Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4575dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e398980",
   "metadata": {},
   "source": [
    "## Step-2:Load the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f32c8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\Snigdha\\\\New folder\\\\Studies\\\\PROJECTS\\\\Predict closed questions on Stack Overflow\\\\train-sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a329087b",
   "metadata": {},
   "source": [
    "## Step-3:Separate the data into input (X) and target (y) variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcaa599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df['BodyMarkdown'].values\n",
    "y = df['OpenStatus'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e75bda",
   "metadata": {},
   "source": [
    "## Step-4:Encode Labels using LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cc3b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "binary_labels = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adfffe8",
   "metadata": {},
   "source": [
    "## Step-5:Split the data into training & testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d944368",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,binary_labels, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349e109d",
   "metadata": {},
   "source": [
    "## Step-6:Tokenize the input data using the Keras Tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb286d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b418206a",
   "metadata": {},
   "source": [
    "## Step-7:Pad the input sequences to ensure they all have the same length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c062628",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100  # Max sequence length\n",
    "\n",
    "X_train = pad_sequences(X_train, padding=\"post\", maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding=\"post\", maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d90c2",
   "metadata": {},
   "source": [
    "## Step-8: LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fc03071",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
    "model.add(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dff37d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 50)           15342600  \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                29440     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,372,105\n",
      "Trainable params: 15,372,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806226b9",
   "metadata": {},
   "source": [
    "## Step-9:Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef89844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2762/2762 [==============================] - 422s 152ms/step - loss: -101.7550 - accuracy: 0.1117 - val_loss: -190.9814 - val_accuracy: 0.1147\n",
      "Epoch 2/10\n",
      "2762/2762 [==============================] - 417s 151ms/step - loss: -281.8475 - accuracy: 0.1117 - val_loss: -368.8728 - val_accuracy: 0.1147\n",
      "Epoch 3/10\n",
      "2762/2762 [==============================] - 422s 153ms/step - loss: -461.2683 - accuracy: 0.1117 - val_loss: -547.3309 - val_accuracy: 0.1147\n",
      "Epoch 4/10\n",
      "2762/2762 [==============================] - 432s 156ms/step - loss: -642.4760 - accuracy: 0.1117 - val_loss: -728.8766 - val_accuracy: 0.1147\n",
      "Epoch 5/10\n",
      "2762/2762 [==============================] - 434s 157ms/step - loss: -825.1037 - accuracy: 0.1117 - val_loss: -910.1512 - val_accuracy: 0.1147\n",
      "Epoch 6/10\n",
      "2762/2762 [==============================] - 431s 156ms/step - loss: -1007.9784 - accuracy: 0.1117 - val_loss: -1088.2952 - val_accuracy: 0.1147\n",
      "Epoch 7/10\n",
      "2762/2762 [==============================] - 438s 159ms/step - loss: -1191.2268 - accuracy: 0.1117 - val_loss: -1269.8612 - val_accuracy: 0.1147\n",
      "Epoch 8/10\n",
      "2762/2762 [==============================] - 784s 284ms/step - loss: -1373.8042 - accuracy: 0.1117 - val_loss: -1449.1686 - val_accuracy: 0.1147\n",
      "Epoch 9/10\n",
      "2762/2762 [==============================] - 831s 301ms/step - loss: -1556.6500 - accuracy: 0.1117 - val_loss: -1629.3986 - val_accuracy: 0.1147\n",
      "Epoch 10/10\n",
      "2762/2762 [==============================] - 454s 164ms/step - loss: -1738.8813 - accuracy: 0.1117 - val_loss: -1809.3702 - val_accuracy: 0.1147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bd08940f70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14951c5a",
   "metadata": {},
   "source": [
    "## Step-10:Evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22418cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1316/1316 [==============================] - 20s 15ms/step - loss: -1814.2866 - accuracy: 0.1107\n",
      "Test accuracy: 0.11071241647005081\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Test accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2b491a",
   "metadata": {},
   "source": [
    "## Step-11:Predictions on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cefac2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "The question is likely to be closed.\n"
     ]
    }
   ],
   "source": [
    "new_question = \"How can I solve this error in my code?\"\n",
    "new_question_seq = tokenizer.texts_to_sequences([new_question])\n",
    "new_question_padded = pad_sequences(new_question_seq, padding=\"post\", maxlen=maxlen)\n",
    "\n",
    "prediction = model.predict(new_question_padded)\n",
    "\n",
    "if prediction >= 0.5:\n",
    "    print(\"The question is likely to be closed.\")\n",
    "else:\n",
    "    print(\"The question is likely to be open.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac7a64",
   "metadata": {},
   "source": [
    "# Accuaracy score : 11.07%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd101cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorEnv",
   "language": "python",
   "name": "tensorenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
